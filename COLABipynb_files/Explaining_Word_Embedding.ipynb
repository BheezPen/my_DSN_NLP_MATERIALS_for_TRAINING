{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5eouydPOiGFx3jjWLQX96"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANING MODEL BUILDING WITH EMPHASIS ON LEARNING EMBEDDING AND NOT USING THE PRETRAINED MODEL FOR EMBEDDING"
      ],
      "metadata": {
        "id": "-Usu5iF1IeXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # Import TensorFlow library\n",
        "from tensorflow import keras  # Import Keras module from TensorFlow\n",
        "from tensorflow.keras import layers  # Import layers module from Keras\n",
        "\n",
        "# --- Data Preparation (Dummy Data for Demonstration) --- # Define example parameters for the data\n",
        "max_tokens = 10000  # Example vocabulary size (number of unique words/tokens)\n",
        "input_length = 50   # Example sequence length (maximum length of input sequences)\n",
        "batch_size = 32     # Batch size for training\n",
        "\n",
        "# Create dummy training dataset using tf.data.Dataset\n",
        "int_train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.random.uniform(shape=(1000, input_length), minval=0, maxval=max_tokens, dtype=tf.int64),  # Input sequences (random integers)\n",
        "     tf.random.uniform(shape=(1000,), minval=0, maxval=2, dtype=tf.int64))  # Target labels (random 0 or 1)\n",
        ").batch(batch_size)  # Batch the dataset into batches of size batch_size\n",
        "\n",
        "# Create dummy validation dataset using tf.data.Dataset\n",
        "int_val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.random.uniform(shape=(200, input_length), minval=0, maxval=max_tokens, dtype=tf.int64),  # Input sequences (random integers)\n",
        "     tf.random.uniform(shape=(200,), minval=0, maxval=2, dtype=tf.int64))  # Target labels (random 0 or 1)\n",
        ").batch(batch_size)  # Batch the dataset into batches of size batch_size\n",
        "\n",
        "# --- Model Definition ---\n",
        "# Define the input layer, taking integer sequences as input\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")  # shape=(None,) allows variable sequence lengths\n",
        "\n",
        "# Embedding layer: Converts integer sequences to dense vectors (embeddings)\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)  # 256-dimensional embeddings\n",
        "\n",
        "# Bidirectional LSTM layer: Processes the embedded sequences in both forward and backward directions\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)  # 32 units in each LSTM layer\n",
        "\n",
        "# Dropout layer: Applies dropout regularization to prevent overfitting\n",
        "x = layers.Dropout(0.5)(x)  # Dropout rate of 0.5 (50%)\n",
        "\n",
        "# Output layer: Produces a probability for binary classification (0 or 1)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # Sigmoid activation for binary output\n",
        "\n",
        "# Create the Keras model by specifying the input and output layers\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# --- Model Compilation ---\n",
        "\n",
        "# Compile the model by specifying the optimizer, loss function, and metrics\n",
        "model.compile(optimizer=\"rmsprop\",  # RMSprop optimizer\n",
        "              loss=\"binary_crossentropy\",  # Binary cross-entropy loss for binary classification\n",
        "              metrics=[\"accuracy\"])  # Track accuracy during training\n",
        "\n",
        "# --- Model Summary ---\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "\n",
        "# Define callbacks to be used during training\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",  # File path to save the model\n",
        "                                    save_best_only=True)  # Save only the best model (based on validation loss)\n",
        "]\n",
        "\n",
        "# --- Model Training ---\n",
        "\n",
        "# Train the model using the training data and validate on the validation data\n",
        "model.fit(int_train_ds,  # Training dataset\n",
        "          validation_data=int_val_ds,  # Validation dataset\n",
        "          epochs=10,  # Number of epochs to train for\n",
        "          callbacks=callbacks)  # Apply the defined callbacks\n",
        "\n",
        "# --- Load Best Model ---\n",
        "\n",
        "# Load the best saved model from the specified file path\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "\n",
        "# --- Model Evaluation ---\n",
        "\n",
        "# Evaluate the model on the validation dataset and print the results\n",
        "loss, accuracy = model.evaluate(int_val_ds)\n",
        "print(f\"Validation loss: {loss}, Validation accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "5rXDv02LBKHT",
        "outputId": "ab541c3c-0fe8-4008-f2f0-f7b08919a7d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m73,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,634,049\u001b[0m (10.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,634,049</span> (10.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,634,049\u001b[0m (10.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,634,049</span> (10.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.4853 - loss: 0.6930 - val_accuracy: 0.4800 - val_loss: 0.6967\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.5542 - loss: 0.6816 - val_accuracy: 0.4800 - val_loss: 0.7014\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.6541 - loss: 0.6535 - val_accuracy: 0.5550 - val_loss: 0.7005\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.8959 - loss: 0.5060 - val_accuracy: 0.4750 - val_loss: 1.0188\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.9808 - loss: 0.0763 - val_accuracy: 0.5150 - val_loss: 1.5288\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.5000 - val_loss: 1.8010\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.4800 - val_loss: 2.2196\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.5050 - val_loss: 2.2816\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5050 - val_loss: 2.4917\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 6.1932e-04 - val_accuracy: 0.4950 - val_loss: 2.6745\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4701 - loss: 0.6971\n",
            "Validation loss: 0.6967070698738098, Validation accuracy: 0.47999998927116394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "sFt-DFH4Ah8p",
        "outputId": "b43f453c-b9cd-445f-e2c9-2930b7dd9abe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'inputs = keras.Input(shape=(None,), dtype=\"int64\")\\nembedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\\nx = layers.Bidirectional(layers.LSTM(32))(embedded)\\nx = layers.Dropout(0.5)(x)\\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\\nmodel = keras.Model(inputs, outputs)\\nmodel.compile(optimizer=\"rmsprop\",\\n loss=\"binary_crossentropy\",\\n metrics=[\"accuracy\"])\\nmodel.summary()\\ncallbacks = [\\n keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\\n save_best_only=True)\\n]\\nmodel.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\\n callbacks=callbacks)\\nmodel = keras.models.load_model(\"embeddings_bidir_gru.keras\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        " loss=\"binary_crossentropy\",\n",
        " metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "callbacks = [\n",
        " keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        " save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
        " callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HERE, EXPLAININ THE PRETRAINED EMBEDDING MODELS, WORD2VEC AND GLOVE"
      ],
      "metadata": {
        "id": "TtSDg7chI1Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api  # Import the Gensim downloader for pre-trained models\n",
        "from sklearn.manifold import TSNE  # Import t-SNE for dimensionality reduction (visualization)\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib for plotting\n",
        "\n",
        "# --- 1. Load Pre-trained Word2Vec Model ---\n",
        "\n",
        "# Load the pre-trained Word2Vec model trained on Google News dataset (300-dimensional vectors)\n",
        "# 'word2vec-google-news-300' is the model identifier in Gensim's downloader\n",
        "wv = api.load('word2vec-google-news-300')  # wv stands for word vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mFshbbMAu3e",
        "outputId": "6f1c3f5f-42c9-4f58-91b6-e266a93a30d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=-------------------------------------------------] 3.3% 54.2/1662.8MB downloaded"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Example 1: Semantic Similarity ---\n",
        "\n",
        "# Calculate and print the cosine similarity between word vectors\n",
        "# Cosine similarity measures how similar two vectors are (between -1 and 1)\n",
        "print(wv.similarity('king', 'queen'))  # Similarity between 'king' and 'queen' (should be high)\n",
        "print(wv.similarity('man', 'woman'))  # Similarity between 'man' and 'woman' (should be high)\n",
        "print(wv.similarity('king', 'man'))  # Similarity between 'king' and 'man' (should be high)\n",
        "print(wv.similarity('king', 'car'))  # Similarity between 'king' and 'car' (should be low)"
      ],
      "metadata": {
        "id": "0Qj8eXE5I_fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Example 2: Analogy ---\n",
        "\n",
        "# Find words most similar to 'king' + 'woman' - 'man' (should be close to 'queen')\n",
        "# This demonstrates the ability of Word2Vec to solve analogy problems\n",
        "result = wv.most_similar(positive=['king', 'woman'], negative=['man'])\n",
        "print(result)"
      ],
      "metadata": {
        "id": "LYPCVUngJCIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Example 2: Analogy ---\n",
        "\n",
        "# Find words most similar to 'king' + 'woman' - 'man' (should be close to 'queen')\n",
        "# This demonstrates the ability of Word2Vec to solve analogy problems\n",
        "\n",
        "result = wv.most_similar(positive=['king', 'girl', 'young'], negative=['man', 'adult'])\n",
        "print(result)"
      ],
      "metadata": {
        "id": "geBxgYeFMqWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 4. Example 3: Getting the Vector for a Word ---\n",
        "\n",
        "# Retrieve the vector representation of the word 'king'\n",
        "vector_king = wv['king']\n",
        "print(vector_king)  # Print the vector (300 numbers)"
      ],
      "metadata": {
        "id": "9w1ct_PfJD5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Example 4: Checking if a Word Exists in the Vocabulary ---\n",
        "\n",
        "# Check if the word 'cat' exists in the Word2Vec vocabulary\n",
        "if 'cat' in wv:\n",
        "    print(\"Cat is in the vocabulary\")\n",
        "else:\n",
        "    print(\"Cat is not in the vocabulary\")"
      ],
      "metadata": {
        "id": "Htb86HVpPVV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Example 5: Visualizing Embeddings (using t-SNE) ---\n",
        "\n",
        "# List of words to visualize\n",
        "words = ['king', 'queen', 'man', 'woman', 'prince', 'princess', 'cat', 'dog', 'library', 'table', 'throne', 'chair']\n",
        "\n",
        "# Get the vector representations for the words (only if they are in the vocabulary)\n",
        "embeddings = [wv[word] for word in words if word in wv]\n",
        "\n",
        "# Convert the list of embeddings to a 2D NumPy array\n",
        "import numpy as np  # Import NumPy for array manipulation\n",
        "embeddings = np.array(embeddings) # Convert the list of embeddings to a NumPy array\n",
        "\n",
        "# Reduce the dimensionality of the vectors to 2D for visualization using t-SNE\n",
        "# t-SNE (t-Distributed Stochastic Neighbor Embedding) is a technique for visualizing high-dimensional data\n",
        "# Set perplexity to a value less than the number of samples (8 in this case)\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=42)  # Reduce to 2 dimensions, perplexity=5\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "# Create a scatter plot of the 2D embeddings\n",
        "plt.figure(figsize=(8, 6))  # Set the figure size\n",
        "for i, word in enumerate(words):\n",
        "    if word in wv:  # Only plot if the word is in the vocabulary\n",
        "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1])  # Plot the point\n",
        "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))  # Add the word label\n",
        "plt.title('Word2Vec Embeddings Visualization (t-SNE)')  # Set the plot title\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "ZtWT0GcxQGmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Example 5: Visualizing Embeddings (using t-SNE) ---\n",
        "\n",
        "# List of words to visualize\n",
        "words = ['king', 'queen', 'prince', 'princess', 'man', 'woman',\n",
        "         'cat', 'dog', 'kitten', 'puppy',\n",
        "         'book', 'library', 'page', 'author',\n",
        "         'chair', 'table', 'furniture', 'sofa']\n",
        "\n",
        "# Get the vector representations for the words (only if they are in the vocabulary)\n",
        "embeddings = [wv[word] for word in words if word in wv]\n",
        "\n",
        "# Convert the list of embeddings to a 2D NumPy array\n",
        "import numpy as np  # Import NumPy for array manipulation\n",
        "embeddings = np.array(embeddings) # Convert the list of embeddings to a NumPy array\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=42)  # Reduce to 2 dimensions, perplexity=5\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "# Create a scatter plot of the 2D embeddings\n",
        "plt.figure(figsize=(8, 6))  # Set the figure size\n",
        "for i, word in enumerate(words):\n",
        "    if word in wv:  # Only plot if the word is in the vocabulary\n",
        "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1])  # Plot the point\n",
        "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))  # Add the word label\n",
        "plt.title('Word2Vec Embeddings Visualization (t-SNE)')  # Set the plot title\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "TcNCrsFTS5-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW LETS USE GLOVE TECHNIQUE"
      ],
      "metadata": {
        "id": "OT5JujiqVOrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "id": "9W_k1gLNWQyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (Your load_glove_vectors, sentences_train, sentences_val, text_vectorization, embedding_dim, etc. code) ...\n",
        "\n",
        "# 1. Prepare your training and validation sentences\n",
        "sentences_train = [\"This is a sample sentence.\", \"Another sentence with more words.\", \"Train data example one\", \"Train data example two\"]\n",
        "sentences_val = [\"Validation sentence one.\", \"Validation sentence two.\"]\n",
        "all_sentences = sentences_train + sentences_val  # Combine for consistent vocabulary\n",
        "\n",
        "# 2. Create a TextVectorization layer with a larger vocabulary size\n",
        "max_tokens = 10000  # Increase the maximum size of the vocabulary to match the training data\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=10  # Adjust according to your data\n",
        ")\n",
        "\n",
        "# 3. Adapt the TextVectorization layer to all sentences\n",
        "text_vectorization.adapt(all_sentences)\n",
        "\n",
        "# 4. Load GloVe vectors\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")\n",
        "\n",
        "# 5. Create the embedding matrix using the consistent vocabulary\n",
        "embedding_dim = 100\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# 6. Create the Embedding layer\n",
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")\n",
        "# 7. Vectorize your training and validation data\n",
        "int_train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (text_vectorization(sentences_train), labels_train)  # Use text_vectorization to transform text to indices\n",
        ").batch(2)\n",
        "\n",
        "int_val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (text_vectorization(sentences_val), labels_val)  # Use text_vectorization to transform text to indices\n",
        ").batch(2)\n",
        "\n",
        "# 8. Build, compile, and train your model (rest of the code remains the same)\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "# Now 'int_train_ds' and 'int_val_ds' have indices matching the embedding layer\n",
        "\n",
        "# --- Modified Functions using GloVe Vocabulary ---\n",
        "\n",
        "def get_glove_vector(word, embeddings_index):\n",
        "    \"\"\"Retrieves the GloVe vector for a word.\"\"\"\n",
        "    return embeddings_index.get(word)\n",
        "\n",
        "def glove_similarity(word1, word2, embeddings_index):\n",
        "    \"\"\"Calculates cosine similarity between two words.\"\"\"\n",
        "    vec1 = get_glove_vector(word1, embeddings_index)\n",
        "    vec2 = get_glove_vector(word2, embeddings_index)\n",
        "    if vec1 is not None and vec2 is not None:\n",
        "        return cosine_similarity([vec1], [vec2])[0, 0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def find_most_similar(word, embeddings_index, top_n=5):\n",
        "    \"\"\"Finds the top N most similar words to a given word.\"\"\"\n",
        "    word_vector = get_glove_vector(word, embeddings_index)\n",
        "    if word_vector is None:\n",
        "        return None\n",
        "\n",
        "    similarities = []\n",
        "    for vocab_word, vector in embeddings_index.items():\n",
        "        if vocab_word != word:\n",
        "            similarity = cosine_similarity([word_vector], [vector])[0, 0]\n",
        "            similarities.append((vocab_word, similarity))\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def check_word_vector(word, embeddings_index):\n",
        "    \"\"\"Checks if a word has a GloVe vector.\"\"\"\n",
        "    if get_glove_vector(word, embeddings_index) is not None:\n",
        "        print(f\"'{word}' has a GloVe vector.\")\n",
        "    else:\n",
        "        print(f\"'{word}' does not have a GloVe vector.\")\n",
        "\n",
        "def get_word_vector(word, embeddings_index):\n",
        "    \"\"\"Retrieves the GloVe vector for a word.\"\"\"\n",
        "    vector = get_glove_vector(word, embeddings_index)\n",
        "    if vector is not None:\n",
        "        print(f\"Vector for '{word}': {vector}\")\n",
        "    else:\n",
        "        print(f\"'{word}' has no vector.\")\n",
        "\n",
        "def visualize_embeddings(words, embeddings_index):\n",
        "    \"\"\"Visualizes GloVe embeddings using t-SNE.\"\"\"\n",
        "    embeddings = [get_glove_vector(word, embeddings_index) for word in words if get_glove_vector(word, embeddings_index) is not None]\n",
        "    words_filtered = [word for word in words if get_glove_vector(word, embeddings_index) is not None]\n",
        "\n",
        "    if not embeddings:\n",
        "        print(\"No embeddings to visualize.\")\n",
        "        return\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, word in enumerate(words_filtered):\n",
        "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1])\n",
        "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
        "    plt.title('GloVe Embeddings Visualization (t-SNE)')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WtI_pt2ydBTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Usage Examples ---\n",
        "\n",
        "# Examples of Semantic Similarity\n",
        "print(f\"Similarity ('king', 'queen'): {glove_similarity('king', 'queen', embeddings_index)}\")\n",
        "print(f\"Similarity ('man', 'woman'): {glove_similarity('man', 'woman', embeddings_index)}\")\n",
        "print(f\"Similarity ('king', 'man'): {glove_similarity('king', 'man', embeddings_index)}\")\n",
        "print(f\"Similarity ('king', 'car'): {glove_similarity('king', 'car', embeddings_index)}\")\n",
        "print(f\"Similarity ('cat', 'dog'): {glove_similarity('cat', 'dog', embeddings_index)}\")\n"
      ],
      "metadata": {
        "id": "whgIQ8Ffd8A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples of Finding Similar Words (Continued)\n",
        "print(f\"Most similar to 'cat': {find_most_similar('cat', embeddings_index)}\")\n",
        "print(f\"Most similar to 'book': {find_most_similar('book', embeddings_index)}\")"
      ],
      "metadata": {
        "id": "nL1D42dheE0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples of Checking Word Vector Existence\n",
        "check_word_vector(\"king\", embeddings_index)\n",
        "check_word_vector(\"randomword\", embeddings_index)"
      ],
      "metadata": {
        "id": "eMrEdXEnf_Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples of Getting the Vector for a Word\n",
        "get_word_vector(\"queen\", embeddings_index)\n",
        "get_word_vector(\"anotherword\", embeddings_index)"
      ],
      "metadata": {
        "id": "5bjF5xZmgBDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Visualization\n",
        "#words_to_visualize = ['king', 'queen', 'man', 'woman', 'cat', 'dog', 'book', 'library']\n",
        "#visualize_embeddings(words_to_visualize, embeddings_index)"
      ],
      "metadata": {
        "id": "Dyd2zeeUgDUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_embeddings(words, embeddings_index):\n",
        "    \"\"\"Visualizes GloVe embeddings using t-SNE.\"\"\"\n",
        "    embeddings = [get_glove_vector(word, embeddings_index) for word in words if get_glove_vector(word, embeddings_index) is not None]\n",
        "    words_filtered = [word for word in words if get_glove_vector(word, embeddings_index) is not None]\n",
        "\n",
        "    if not embeddings:\n",
        "        print(\"No embeddings to visualize.\")\n",
        "        return\n",
        "\n",
        "    # Convert the list of embeddings to a NumPy array\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    # Lower the perplexity to be significantly less than the number of samples\n",
        "    tsne = TSNE(n_components=2, perplexity=3, random_state=42)  # Reduced perplexity to 3\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, word in enumerate(words_filtered):\n",
        "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1])\n",
        "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
        "    plt.title('GloVe Embeddings Visualization (t-SNE)')\n",
        "    plt.show()\n",
        "\n",
        "words_to_visualize = ['king', 'queen', 'man', 'woman', 'cat', 'dog', 'book', 'library']\n",
        "visualize_embeddings(words_to_visualize, embeddings_index)"
      ],
      "metadata": {
        "id": "kHLl7xb4iHme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_visualize = ['king', 'queen', 'prince', 'princess', 'man', 'woman',\n",
        "         'cat', 'dog', 'kitten', 'puppy',\n",
        "         'book', 'library', 'page', 'author',\n",
        "         'chair', 'table', 'furniture', 'sofa']\n",
        "\n",
        "visualize_embeddings(words_to_visualize, embeddings_index)"
      ],
      "metadata": {
        "id": "ejgaYpGykRJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "--- Use Cases for Word2Vec and GloVe ---\n",
        "\n",
        "1. Semantic Similarity and Relatedness:\n",
        "- Finding synonyms and related words.\n",
        "- Measuring the semantic distance between words or documents.\n",
        "- Example: Building a search engine that understands the meaning of queries.\n",
        "\n",
        "2. Analogy Tasks:\n",
        "- Solving analogy problems like \"king - man + woman = queen\".\n",
        "- Example: Building a question-answering system that can reason about relationships between words.\n",
        "\n",
        "3. Feature Engineering for NLP Models:\n",
        "- Using pre-trained embeddings as input features for deep learning models.\n",
        "- Example: Improving the performance of sentiment analysis, text classification, or machine translation models.\n",
        "\n",
        "4. Information Retrieval:\n",
        "- Finding documents that are semantically similar to a query.\n",
        "- Example: Building a document retrieval system that understands the meaning of documents.\n",
        "\n",
        "5. Word Sense Disambiguation:\n",
        "- Identifying the correct meaning of a word in a given context.\n",
        "- Example: Building a system that can understand the different meanings of polysemous words.\n",
        "\n",
        "6. Recommendation Systems:\n",
        "- Recommending items based on their semantic similarity.\n",
        "- Example: Building a movie recommendation system that suggests movies similar to those a user has watched.\n",
        "\n",
        "7. Text Summarization:\n",
        "- Identifying the most important sentences or phrases in a document.\n",
        "- Example: Building a system that can generate concise summaries of long documents.\n",
        "\n",
        "8. Machine Translation:\n",
        "- Representing words in different languages in a shared embedding space.\n",
        "- Example: Building a system that can translate text from one language to another while preserving meaning.\n",
        "\n",
        "Key Differences (Word2Vec vs. GloVe):\n",
        "\n",
        "Word2Vec:\n",
        "- Predicts context words given a target word (or vice versa).\n",
        "- Captures local context information.\n",
        "- Better for capturing semantic relationships between words that appear in similar contexts.\n",
        "\n",
        "GloVe:\n",
        "- Leverages global word co-occurrence statistics.\n",
        "- Captures global relationships between words.\n",
        "- Better for capturing overall word similarity and relatedness."
      ],
      "metadata": {
        "id": "lMzuoBBgJKFo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Rl67af7JJcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}